{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mobileNetv2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GqEPPkXhYcVO","colab_type":"text"},"source":["## imports"]},{"cell_type":"code","metadata":{"id":"-fKntb3otSVo","colab_type":"code","outputId":"c286e0ba-8393-468a-f62e-7577dcafac2f","executionInfo":{"status":"ok","timestamp":1556277388646,"user_tz":-330,"elapsed":1887,"user":{"displayName":"Akash Jadhav","photoUrl":"https://lh5.googleusercontent.com/-yXv9Ny7rXxE/AAAAAAAAAAI/AAAAAAAAAAc/zGjp0Qa7nWU/s64/photo.jpg","userId":"00643688276017227396"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","tf.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.13.1'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"X5xTcKtB66Im","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbHMOMNZvXXa","colab_type":"code","outputId":"d6410a96-18e3-40ab-eeca-1b7246243ff7","executionInfo":{"status":"ok","timestamp":1556277389295,"user_tz":-330,"elapsed":1590,"user":{"displayName":"Akash Jadhav","photoUrl":"https://lh5.googleusercontent.com/-yXv9Ny7rXxE/AAAAAAAAAAI/AAAAAAAAAAc/zGjp0Qa7nWU/s64/photo.jpg","userId":"00643688276017227396"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import keras \n","keras.__version__"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'2.2.4'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"H2JJducxXQf-","colab_type":"code","outputId":"9098116c-b2f2-4ff8-88a9-bf5893816830","executionInfo":{"status":"ok","timestamp":1556277435873,"user_tz":-330,"elapsed":1567,"user":{"displayName":"Akash Jadhav","photoUrl":"https://lh5.googleusercontent.com/-yXv9Ny7rXxE/AAAAAAAAAAI/AAAAAAAAAAc/zGjp0Qa7nWU/s64/photo.jpg","userId":"00643688276017227396"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import matplotlib\n","print('matplotlib: {}'.format(matplotlib.__version__))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["matplotlib: 3.0.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0WSSxJYbXYZB","colab_type":"code","outputId":"cb025a7d-52d8-4f4c-8eab-7ba9490abbb5","executionInfo":{"status":"ok","timestamp":1556277466650,"user_tz":-330,"elapsed":2051,"user":{"displayName":"Akash Jadhav","photoUrl":"https://lh5.googleusercontent.com/-yXv9Ny7rXxE/AAAAAAAAAAI/AAAAAAAAAAc/zGjp0Qa7nWU/s64/photo.jpg","userId":"00643688276017227396"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","pd.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.24.2'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"IremqxgHXd7E","colab_type":"code","outputId":"56ab17c3-62e0-421a-81b4-83882dc3339d","executionInfo":{"status":"ok","timestamp":1556277491829,"user_tz":-330,"elapsed":2023,"user":{"displayName":"Akash Jadhav","photoUrl":"https://lh5.googleusercontent.com/-yXv9Ny7rXxE/AAAAAAAAAAI/AAAAAAAAAAc/zGjp0Qa7nWU/s64/photo.jpg","userId":"00643688276017227396"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import cv2\n","print(cv2.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3.4.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZUQjXI-GXgda","colab_type":"code","outputId":"211ea1c4-0c56-48ff-d141-1ac6614f9b34","executionInfo":{"status":"ok","timestamp":1556277517037,"user_tz":-330,"elapsed":1462,"user":{"displayName":"Akash Jadhav","photoUrl":"https://lh5.googleusercontent.com/-yXv9Ny7rXxE/AAAAAAAAAAI/AAAAAAAAAAc/zGjp0Qa7nWU/s64/photo.jpg","userId":"00643688276017227396"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","np.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.16.3'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"NklR0CZVXusj","colab_type":"code","outputId":"55cb8e7f-09c0-45a2-d1bc-4c2434440e55","executionInfo":{"status":"ok","timestamp":1556277569936,"user_tz":-330,"elapsed":4336,"user":{"displayName":"Akash Jadhav","photoUrl":"https://lh5.googleusercontent.com/-yXv9Ny7rXxE/AAAAAAAAAAI/AAAAAAAAAAc/zGjp0Qa7nWU/s64/photo.jpg","userId":"00643688276017227396"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!python --version"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Python 3.6.7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-KCvRaPqlr27","colab_type":"text"},"source":["# Step 1: Download Dataset"]},{"cell_type":"markdown","metadata":{"id":"2-iK-9tpWU-y","colab_type":"text"},"source":["**Shenzhen Hospital X-ray Set: **X-ray images in this data set have been collected by Shenzhen No.3 Hospital in Shenzhen, Guangdong providence, China. The x-rays were acquired as part of the routine care at Shenzhen Hospital. The set contains images in JPEG format. "]},{"cell_type":"code","metadata":{"id":"0jxoj7VSjmN-","colab_type":"code","colab":{}},"source":["!wget https://openi.nlm.nih.gov/imgs/collections/ChinaSet_AllFiles.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqbUNbEqrk8u","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nS6q-ffUjvaq","colab_type":"code","colab":{}},"source":["!unzip ChinaSet_AllFiles.zip -d images/ "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CN5dt9cjqpAz","colab_type":"code","colab":{}},"source":["ls images/ChinaSet_AllFiles"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"amM45zoPlNy2","colab_type":"code","colab":{}},"source":["rm ChinaSet_AllFiles.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCBTUH3ukvxa","colab_type":"code","colab":{}},"source":["rm images/ChinaSet_AllFiles/CXR_png/Thumbs.db"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3WGFMFpK-4Zr","colab_type":"code","colab":{}},"source":["!rm -rf images/ChinaSet_AllFiles/ClinicalReadings/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HxR-oOS0-9b5","colab_type":"code","colab":{}},"source":["!rm images/ChinaSet_AllFiles/NLM-ChinaCXRSet-ReadMe.docx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_OhCupQPlLo0","colab_type":"text"},"source":["# Step 2: Prepare Dataset csv file"]},{"cell_type":"code","metadata":{"id":"yXYUwZEfjueC","colab_type":"code","colab":{}},"source":["ls  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"45uCRFJdjqh7","colab_type":"code","colab":{}},"source":["# prepare dataset.csv file\n","\n","import os\n","import csv\n","\n","def parseTxtFile(filename):\n","  print(\"filename is ====> \", filename)\n","  temp = filename.split(\".\" )\n","  temp = str(temp[0])\n","  temp = temp.split(\"_\")\n","  label = temp[2]\n","  text = [filename, label]\n","\n","  with open('dataset.csv', 'a') as csvFile:\n","    writer = csv.writer(csvFile)\n","    writer.writerow(text)\n","    csvFile.close()\n","\n","        \n","             \n","\n","datasetDir = os.path.join(os.getcwd(), \"images/ChinaSet_AllFiles/CXR_png/\")\n","\n","for file_name in os.listdir(datasetDir):\n","             parseTxtFile(file_name)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4drl6S4Hspzi","colab_type":"code","colab":{}},"source":["import pandas as pd\n","original_dataset = pd.read_csv(\"dataset.csv\", header=None)\n","print(original_dataset.shape)\n","print(\"\\n\\n\",original_dataset.head())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x184VXAjuAq0","colab_type":"code","colab":{}},"source":["X = original_dataset[0]\n","y = original_dataset[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vdhq3cQluLb8","colab_type":"code","colab":{}},"source":["X.head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_E81QRguQdN","colab_type":"code","colab":{}},"source":["y.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tin9iRl8tGX5","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFKVlYkjuuPK","colab_type":"code","colab":{}},"source":["print(\"X_train: \",X_train.size, y_train.size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvM4nfVIu2bQ","colab_type":"code","colab":{}},"source":["print(\"X_test: \",X_test.size, y_test.size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTgqgoKSvILv","colab_type":"code","colab":{}},"source":["print(\"X_val: \",X_val.size, y_val.size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DvdXiBNy_pA-","colab_type":"text"},"source":["# Step 3: Preprocess image"]},{"cell_type":"code","metadata":{"id":"60SL_A0j95c6","colab_type":"code","colab":{}},"source":["ls images/ChinaSet_AllFiles/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"37JBlv_QxKMk","colab_type":"code","colab":{}},"source":["import random\n","import pathlib\n","\n","datasetDir = os.path.join(os.getcwd(), \"images/ChinaSet_AllFiles/\")\n","data_root = pathlib.Path(datasetDir)\n","print(data_root,\"=======\")\n","\n","\n","all_image_paths = list(data_root.glob('*/*'))\n","all_image_paths = [str(path) for path in all_image_paths]\n","\n","image_count = len(all_image_paths)\n","image_count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j1YpxNTUyik5","colab_type":"code","colab":{}},"source":["all_image_paths[:10]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DcT7qvirNnYe","colab_type":"code","colab":{}},"source":["all_image_paths[2]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vFh2QAZk_y2H","colab_type":"text"},"source":["### Code to read image in grayscale format"]},{"cell_type":"code","metadata":{"id":"zseYbZkYJ57K","colab_type":"code","colab":{}},"source":["# # Resize image and normalizes it\n","\n","# def preprocess_image(image):\n","#   # convert raw image into tensor\n","#   img_tensor = tf.image.decode_jpeg(image, channels=3)\n","#   img_tensor = tf.image.rgb_to_grayscale(img_tensor)\n","  \n","#   # resize image to 128*128\n","#   image = tf.image.resize_images(img_tensor, [128, 128])\n","\n","#   # Removes dimensions of size 1 from the shape of a tensor.\n","#   image = tf.squeeze(image)\n","#   # normalize to [0,1] range\n","#   image /= 255.0  \n","#   return image"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x_rVifjR_503","colab_type":"text"},"source":["### Code to read image in *RGB* format"]},{"cell_type":"code","metadata":{"id":"CQbsK7nm_xTt","colab_type":"code","colab":{}},"source":["# Resize image and normalizes it\n","\n","def preprocess_image(image):\n","  # convert raw image into tensor\n","  img_tensor = tf.image.decode_jpeg(image, channels=3)\n","  \n","  # resize image to 128*128\n","  image = tf.image.resize_images(img_tensor, [224, 224])\n","  # normalize to [0,1] range\n","  image /= 255.0  \n","  return image"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uODKi7rmAGE0","colab_type":"text"},"source":["### Load and preprocess function"]},{"cell_type":"code","metadata":{"id":"wSKdkSYtwkar","colab_type":"code","colab":{}},"source":["# reads image and call functin to resize it\n","def load_and_preprocess_image(path):\n","  image = tf.read_file(path)\n","  return preprocess_image(image)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ha9gbaF1EAM3","colab_type":"text"},"source":["## Test preprocessing functions if it's working or not"]},{"cell_type":"code","metadata":{"id":"3k7N7aGp5yXJ","colab_type":"code","colab":{}},"source":["img_tensor = load_and_preprocess_image(all_image_paths[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBswsVDZDeJl","colab_type":"code","colab":{}},"source":["sess = tf.InteractiveSession()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvVPZVvTArh8","colab_type":"code","colab":{}},"source":["print(repr(img_tensor.shape))\n","print(img_tensor.dtype)\n","\n","print(img_tensor.eval().min())\n","print(img_tensor.eval().max())\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3TErgNqFBgm5","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","\n","image_path = all_image_paths[0]\n","img = load_and_preprocess_image(image_path)\n","\n","print(img.shape)\n","print(img.eval().ndim)\n","\n","plt.imshow(img.eval())\n","plt.grid(False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O09iU21CP5Jm","colab_type":"code","colab":{}},"source":["sess.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V2pS0WjqdB6G","colab_type":"text"},"source":["### RGB plot V/S Grayscale Plot"]},{"cell_type":"code","metadata":{"id":"_CY_SHVjUS-F","colab_type":"code","colab":{}},"source":["import cv2\n","img = cv2.imread(all_image_paths[0], 0)\n","print(img.shape)\n","\n","%matplotlib inline\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","plt.imshow(img, cmap = plt.cm.gray)\n","plt.grid(False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"46deuj15V1lu","colab_type":"code","colab":{}},"source":["import cv2\n","img = cv2.imread(all_image_paths[0])\n","\n","print(img.shape)\n","\n","%matplotlib inline\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","plt.imshow(img)\n","plt.grid(False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_yMIBoI8dMbd","colab_type":"text"},"source":["# Step 4: Build a `tf.data.Dataset`"]},{"cell_type":"markdown","metadata":{"id":"RE72eoaACZq7","colab_type":"text"},"source":["https://www.tensorflow.org/guide/performance/datasets\n","\n","GPUs and TPUs can radically reduce the time required to execute a single training step, the CPU processing is prone to becoming the bottleneck. Achieving peak performance requires an efficient input pipeline that delivers data for the next step before the current step has finished. The tf.data API helps to build flexible and efficient input pipelines. feed-dict is the slowest possible way to pass information to TensorFlow and it must be avoided"]},{"cell_type":"markdown","metadata":{"id":"ywvVaeczCwZQ","colab_type":"text"},"source":["\n","**Input Pipeline Structure**\n","\n","A typical TensorFlow training input pipeline can be framed as an ETL process:\n","\n","1. **Extract**: Read data from persistent storage -- either local (e.g. HDD or SSD) or remote (e.g. GCS or HDFS).\n","2. **Transform**: Use CPU cores to parse and perform preprocessing operations on the data such as image decompression, data augmentation transformations (such as random crop, flips, and color distortions), shuffling, and batching.\n","3. **Load**: Load the transformed data onto the accelerator device(s) (for example, GPU(s) or TPU(s)) that execute the machine learning model.\n","\n","This pattern effectively utilizes the CPU, while reserving the accelerator for the heavy lifting of training your model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6H9Z5Mq63nSH"},"source":["## A dataset of images"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GN-s04s-6Luq"},"source":["The easiest way to build a `tf.data.Dataset` is using the `from_tensor_slices` method.\n","\n","Slicing the array of strings, results in a dataset of strings:"]},{"cell_type":"code","metadata":{"id":"aHemGMTyHtFX","colab_type":"code","colab":{}},"source":["type(all_image_paths)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0uyfx7jdNOf","colab_type":"code","colab":{}},"source":["path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uML4JeMmIAvO"},"source":["The `output_shapes` and `output_types` fields describe the content of each item in the dataset. In this case it is a set of scalar binary-strings"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mIsNflFbIK34","colab":{}},"source":["print('shape: ', repr(path_ds.output_shapes))\n","print('type: ', path_ds.output_types)\n","print()\n","print(path_ds)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZjyGcM8OwBJ2"},"source":["Now create a new dataset that loads and formats images on the fly by mapping `preprocess_image` over the dataset of paths."]},{"cell_type":"code","metadata":{"id":"MVeKHHfLiGrs","colab_type":"code","colab":{}},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"D1iba6f4khu-","colab":{}},"source":["image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bcGU76GfHEIm","colab_type":"text"},"source":["### test if dataset api indeed return images"]},{"cell_type":"code","metadata":{"id":"0DB0-OE-O6St","colab_type":"code","colab":{}},"source":["type(image_ds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GDQ2z5coMzNZ","colab_type":"code","colab":{}},"source":["# create a one-shot iterator\n","iterator = path_ds.make_one_shot_iterator()\n","# extract an element\n","next_element = iterator.get_next()\n","img = load_and_preprocess_image(next_element)\n","print(img)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KtQzhVihNTL2","colab_type":"code","colab":{}},"source":["import tensorflow.contrib.eager as tfe\n","import matplotlib.pyplot as plt\n","\n","with tf.Session() as sess:\n","    print(img.eval().max())    \n","    print(img.eval().min())\n","    print(img.shape)\n","    plt.imshow(sess.run(img))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WT3hv5tDcIE9","colab_type":"text"},"source":["## Preparing label dataset"]},{"cell_type":"code","metadata":{"id":"IDOU_2XjGmIZ","colab_type":"code","colab":{}},"source":["# ensure label from image name matches all_image_labels\n","\n","all_image_labels = original_dataset[1]\n","img_filename = lambda i: int(all_image_paths[i].split('/')[-1].split('_')[-1].split('.')[0])\n","\n","for i in range(len(all_image_paths)):\n","  if i<10:\n","    print(img_filename(i),\"-\", all_image_labels[i])\n","  assert(img_filename(i), all_image_labels[i])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dyIrqVwo2Z0A","colab_type":"text"},"source":["Ok now as we dont have assertion error we are good to go"]},{"cell_type":"code","metadata":{"id":"BwBT4vC30ddZ","colab_type":"code","colab":{}},"source":["type(all_image_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"spI-BX_V3OOQ","colab_type":"code","colab":{}},"source":["# convert pandas series object to numpy array\n","all_image_labels = all_image_labels.values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"edMWGwUN4OEf","colab_type":"code","colab":{}},"source":["# Using the same from_tensor_slices method we can build a dataset of labels\n","label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_PPCHGO5msK","colab_type":"code","colab":{}},"source":["# test if label_ds works\n","iterator = label_ds.make_one_shot_iterator()\n","next_element = iterator.get_next()\n","\n","with tf.Session() as sess:\n","  for i in range(10):\n","    print(next_element.eval())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BMpDe9bV8GdV","colab_type":"text"},"source":["## A dataset of (image, label) pairs"]},{"cell_type":"code","metadata":{"id":"41RWoT8S6Ovx","colab_type":"code","colab":{}},"source":["ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n","\n","# The tuples are unpacked into the positional arguments of the mapped function \n","def load_and_preprocess_from_path_label(path, label):\n","  return load_and_preprocess_image(path), label\n","\n","image_label_ds = ds.map(load_and_preprocess_from_path_label)\n","# image_label_ds = image_label_ds.cache()\n","image_label_ds"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t7UiRbJD_fGj","colab_type":"text"},"source":["# Step 5:Train validation and test split"]},{"cell_type":"markdown","metadata":{"id":"bC8BkPvRBmWL","colab_type":"text"},"source":["using a 70/15/15 train/val/test split "]},{"cell_type":"code","metadata":{"id":"MkEN2t5NL9Fz","colab_type":"code","colab":{}},"source":["DATASET_SIZE = original_dataset.shape[0]\n","DATASET_SIZE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"namhOJj399Bf","colab_type":"code","colab":{}},"source":["train_size = int(0.7 * DATASET_SIZE)\n","val_size = int(0.15 * DATASET_SIZE)\n","test_size = int(0.15 * DATASET_SIZE)\n","\n","print(train_size, val_size, test_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O_ieaOiPM-iz","colab_type":"text"},"source":["https://stackoverflow.com/questions/51125266/how-do-i-split-tensorflow-datasets\n","\n","**Take:**\n","\n","Creates a Dataset with at most count elements from this dataset.\n","\n","**Skip:**\n","\n","Creates a Dataset that skips count elements from this dataset.\n","\n","**Note that skip actually iterates over the dataset so it can cause big latency on large dataset**"]},{"cell_type":"code","metadata":{"id":"blHyMC3wLMDF","colab_type":"code","colab":{}},"source":["train_dataset = image_label_ds.take(train_size)\n","test_dataset = image_label_ds.skip(train_size)\n","val_dataset = test_dataset.skip(val_size)\n","test_dataset = test_dataset.take(test_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uotZTqpxQbKD","colab_type":"text"},"source":["### calculate dataset size"]},{"cell_type":"code","metadata":{"id":"vKYelcpnA9a2","colab_type":"code","colab":{}},"source":["itrtor = train_dataset.make_one_shot_iterator()\n","nxt_elmnt = itrtor.get_next()\n","train_count = 0\n","train_positive_label = 0\n","train_neg_label = 0\n","with tf.Session() as sess:\n","#   sess.run(itrtor.initializer)\n","  while(1):\n","    try:\n","      img, label = sess.run(nxt_elmnt)\n","#     print(img.shape)\n","#     print(label.shape)\n","#       print(label)\n","      train_count += 1\n","      if label ==1:\n","        train_positive_label += 1\n","      else:\n","        train_neg_label += 1\n","    except tf.errors.OutOfRangeError:\n","      print(\"End of dataset\")  # \"End of dataset\"\n","      break\n","\n","print(\"train total images: \",train_count)\n","print(\"train positive_label: \",train_positive_label)\n","print(\"train neg_label: \",train_neg_label)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6y5pMxPbBo65","colab_type":"code","colab":{}},"source":["itrtor = test_dataset.make_one_shot_iterator()\n","nxt_elmnt = itrtor.get_next()\n","test_count = 0\n","test_positive_label = 0\n","test_neg_label = 0\n","with tf.Session() as sess:\n","#   sess.run(itrtor.initializer)\n","  while(1):\n","    try:\n","      img, label = sess.run(nxt_elmnt)\n","#     print(img.shape)\n","#     print(label.shape)\n","#       print(label)\n","      test_count += 1\n","      if label ==1:\n","        test_positive_label += 1\n","      else:\n","        test_neg_label += 1\n","    except tf.errors.OutOfRangeError:\n","      print(\"End of dataset\")  # \"End of dataset\"\n","      break\n","\n","print(\"test total images: \",test_count)\n","print(\"test positive_label: \",test_positive_label)\n","print(\"test neg_label: \",test_neg_label)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"384i7TESOS6Q","colab_type":"code","colab":{}},"source":["itrtor = val_dataset.make_one_shot_iterator()\n","nxt_elmnt = itrtor.get_next()\n","val_count = 0\n","val_positive_label = 0\n","val_neg_label = 0\n","with tf.Session() as sess:\n","#   sess.run(itrtor.initializer)\n","  while(1):\n","    try:\n","      img, label = sess.run(nxt_elmnt)\n","#     print(img.shape)\n","#     print(label.shape)\n","#       print(label)\n","      val_count += 1\n","      if label ==1:\n","        val_positive_label += 1\n","      else:\n","        val_neg_label += 1\n","    except tf.errors.OutOfRangeError:\n","      print(\"End of dataset\")  # \"End of dataset\"\n","      break\n","\n","print(\"val total images: \",val_count)\n","print(\"val positive_label: \",val_positive_label)\n","print(\"val neg_label: \",val_neg_label)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZoLad2yOOeoJ","colab_type":"text"},"source":["# Step 6: Augmentation pipeline on train dataset"]},{"cell_type":"markdown","metadata":{"id":"WQ8muaVsXfmN","colab_type":"text"},"source":["https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/"]},{"cell_type":"markdown","metadata":{"id":"RMPmaHOiPt9g","colab_type":"text"},"source":["To augment the dataset it can beneficial to make augmenter functions: a function that receives an image (a tf.Tensor) and returns a new augmented image. By defining functions for each augmentation operation we can easily attach them to datasets and control when they are evaluated. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"d5Y4KYjERBhT","colab_type":"text"},"source":["### Rotation and flipping\n"]},{"cell_type":"markdown","metadata":{"id":"PdZ2aVaSRFAm","colab_type":"text"},"source":["To get the number of times the image is rotated by 90 degrees, we need to use a random function from Tensorflow itself"]},{"cell_type":"code","metadata":{"id":"wyW4lInHOpIW","colab_type":"code","colab":{}},"source":["# def rotate(x: tf.Tensor) -> tf.Tensor:\n","#     \"\"\"Rotation augmentation\n","\n","#     Args:\n","#         x: Image\n","\n","#     Returns:\n","#         Augmented image\n","#     \"\"\"\n","\n","#     # Rotate 0, 90, 180, 270 degrees\n","#     return tf.image.rot90(x, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OhPF--uVSc4z","colab_type":"text"},"source":["Tensorflow has a built-in function that does this for us: random_flip_left_right and random_flip_up_down.\n","\n"]},{"cell_type":"code","metadata":{"id":"73IjwrpeQpc5","colab_type":"code","colab":{}},"source":["# def flip(x: tf.Tensor) -> tf.Tensor:\n","#     \"\"\"Flip augmentation\n","\n","#     Args:\n","#         x: Image to flip\n","\n","#     Returns:\n","#         Augmented image\n","#     \"\"\"\n","#     x = tf.image.random_flip_left_right(x)\n","#     x = tf.image.random_flip_up_down(x)\n","\n","#     return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wDzpngMQVpZY","colab_type":"text"},"source":["### Augmenting the Dataset\n"]},{"cell_type":"markdown","metadata":{"id":"RL_tHnuEV2Ek","colab_type":"text"},"source":["With all functions defined we can combine them in to a single pipeline. Applying these functions to a Tensorflow Dataset is very easy using the map function. The map function takes a function and returns a new and augmented dataset. \n","\n","To drastically increase the speed of these operations we can execute them in parallel, practically all Tensorflow operations support this. With the tf.Data API this is done using the num_parallel_calls parameter of the map function. When this parameter is higher than one functions will be executed in parallel. It is advised to set this parameter to the number of CPUs available.\n","\n","Note: Some of these operations can result in images that have values outside the normal range of [0, 1]. To make sure that these ranges are not exceeded a clipping function such as tf.clip_by_value is recommended.\n","\n"]},{"cell_type":"code","metadata":{"id":"_q8SwxNhWWoa","colab_type":"code","colab":{}},"source":["# AUTOTUNE = tf.data.experimental.AUTOTUNE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n7nraqkNVqhJ","colab_type":"code","colab":{}},"source":["# # Add augmentations\n","# augmentations = [flip, rotate]\n","\n","# # Add the augmentations to the dataset\n","# for f in augmentations:\n","#     # Apply the augmentation, run 4 jobs in parallel.\n","#     aug_dataset = train_dataset.map(f, num_parallel_calls=4)\n","\n","# # Make sure that the values are still in [0, 1]\n","# aug_dataset = aug_dataset.map(lambda x: tf.clip_by_value(x, 0, 1), num_parallel_calls=AUTOTUNE)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7CX4Esm8e5Ap","colab_type":"text"},"source":["# Step 6.5: Data prep in batches"]},{"cell_type":"markdown","metadata":{"id":"qiPpJkIYcMdB","colab_type":"text"},"source":["To train a model with this dataset you will want the data:\n","\n","* To be well shuffled.\n","* To be batched.\n","* To repeat forever.\n","* Batches to be available as soon as possible.\n","\n","These features can be easily added using the `tf.data api`.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BMkf8kG7FZGx","colab_type":"text"},"source":["Make sure to call tf.data.Dataset.shuffle() before applying the heavy transformations (like reading the images, processing them, batching...).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eS0ZpmKWEH8z","colab_type":"text"},"source":["**shuffling dataset and problems related**\n","\n","\n","\n","1.   https://github.com/tensorflow/tensorflow/issues/14857\n","2.   https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle\n","\n"]},{"cell_type":"code","metadata":{"id":"Kqz3rp2SdJG3","colab_type":"code","colab":{}},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8N84N58I-gEH","colab_type":"code","colab":{}},"source":["image_count = 700\n","BATCH_SIZE = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"85AOCtdDXpRR","colab_type":"code","colab":{}},"source":["# this code section has alternative snipet in below code cell\n","\n","# # Setting a shuffle buffer size as large as the dataset ensures that the data is\n","# # completely shuffled.\n","# ds = image_label_ds.shuffle(buffer_size=image_count)\n","# ds = ds.repeat()\n","# ds = ds.batch(BATCH_SIZE)\n","# # `prefetch` lets the dataset fetch batches, in the background while the model is training.\n","# ds = ds.prefetch(buffer_size=AUTOTUNE)\n","# ds"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"InokPqine8gQ","colab_type":"text"},"source":["There are a few things to note here:\n","\n","1. The order is important.\n","\n","  * A `.shuffle` before a `.repeat` would shuffle items across epoch boundaries (some items will ve seen twice before others are seen at all).\n","  * A `.shuffle` after a `.batch` would shuffle the order of the batches, but not shuffle the items across batches.\n","  \n","2. We use a `buffer_size` the same size as the dataset for a full shuffle. Up to the dataset size, large values provide better randomization, but use more memory.\n","\n","3. The shuffle buffer is filled before any elements are pulled from it. So a large `buffer_size` may cause a delay when your Dataset is starting.\n","\n","4. The shuffeled dataset doesn't report the end of a dataset until the shuffle-buffer is completely empty. The Dataset is restarted by `.repeat`, causing another wait for the shuffle-buffer to be filled.\n","\n","\n","This last point can be addressed by using the `tf.data.Dataset.apply` method with the fused `tf.data.experimental.shuffle_and_repeat` function:\n","\n"]},{"cell_type":"code","metadata":{"id":"luNgXKMTOB_o","colab_type":"code","colab":{}},"source":["#this code prepares full dataset\n","\n","# ds = image_label_ds.apply(\n","#   tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n","# ds = ds.batch(BATCH_SIZE)\n","# ds = ds.prefetch(buffer_size=AUTOTUNE)\n","# ds"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b8Y34gs_gBLZ","colab_type":"text"},"source":["### preparing batches/ shuffling"]},{"cell_type":"code","metadata":{"id":"UsvZ1Y8k3n8g","colab_type":"code","colab":{}},"source":["print(train_size, val_size, test_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zahx9nFyqqYl","colab_type":"code","colab":{}},"source":["# Train dataset \n","\n","train_ds = train_dataset.apply(\n","  tf.data.experimental.shuffle_and_repeat(buffer_size=train_size))\n","train_ds = train_ds.batch(BATCH_SIZE)\n","train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n","train_ds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xp3eAMokquqB","colab_type":"code","colab":{}},"source":["# valid dataset \n","\n","valid_ds = val_dataset.apply(\n","  tf.data.experimental.shuffle_and_repeat(buffer_size=val_size))\n","valid_ds = valid_ds.batch(BATCH_SIZE)\n","valid_ds = valid_ds.prefetch(buffer_size=AUTOTUNE)\n","valid_ds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fOx3QwXD9nAd","colab_type":"code","colab":{}},"source":["# test dataset \n","\n","test_ds = test_dataset.apply(\n","  tf.data.experimental.shuffle_and_repeat(buffer_size=val_size))\n","test_ds = test_ds.batch(BATCH_SIZE)\n","test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n","test_ds"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OAjEfPoOfwGj","colab_type":"text"},"source":["### Normalization to [-1, 1]"]},{"cell_type":"markdown","metadata":{"id":"aEhJI4ZmosUE","colab_type":"text"},"source":["**This function applies the \"Inception\" preprocessing which converts\n","the RGB values from [0, 255] to [-1, 1]  ** So before the passing it to the MobilNet model, we need to convert the input from a range of [0,1] to [-1,1].\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"7S-prsRzj1qC","colab_type":"code","colab":{}},"source":["def change_range(image,label):\n","  return 2*image-1, label\n","\n","train_ds = train_ds.map(change_range)\n","valid_ds = valid_ds.map(change_range)\n","test_ds = test_ds.map(change_range)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kZXnQzyUeCVU","colab_type":"text"},"source":["### **Cache**\n","\n","Use `tf.data.Dataset.cache` to easily cache calculations across epochs. This is especially performant if the dataq fits in memory.\n","\n","Here the images are cached, after being pre-precessed (decoded and resized):\n","\n"]},{"cell_type":"code","metadata":{"id":"QuKy1pj8BtdF","colab_type":"code","colab":{}},"source":["# train_dataset = train_dataset.cache()\n","# val_dataset = val_dataset.cache()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qjn99AvYXjSQ","colab_type":"text"},"source":["# Step 7: Training"]},{"cell_type":"markdown","metadata":{"id":"aTxXC-E8gG5F","colab_type":"text"},"source":["## Pipe the dataset to a model using mobilenetV2"]},{"cell_type":"code","metadata":{"id":"NhhjqMIZeh1T","colab_type":"code","colab":{}},"source":["mobile_net = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n","                                               include_top=False,\n","                                               weights='imagenet')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8QuYrqtgIuH","colab_type":"code","colab":{}},"source":["# mobile_net = tf.keras.applications.MobileNetV2(input_shape=(128, 128, 3), include_top=False)\n","mobile_net.trainable=False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XJjXR8LqfITK","colab_type":"text"},"source":["### misc"]},{"cell_type":"code","metadata":{"id":"qSh9pVjgxdaL","colab_type":"code","colab":{}},"source":["# # this code prepares full dataset\n","\n","# ds = image_label_ds.apply(\n","#   tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n","# ds = ds.batch(BATCH_SIZE)\n","# ds = ds.prefetch(buffer_size=AUTOTUNE)\n","# ds\n","\n","# keras_ds = ds.map(change_range)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5DD4YXqspaiE","colab_type":"text"},"source":["The MobileNet returns a 6x6 spatial grid of features for each image.\n","\n","Pass it a batch of images to see:\n","\n"]},{"cell_type":"code","metadata":{"id":"bva4j0y_pbMM","colab_type":"code","colab":{}},"source":["# iterator = train_ds.make_initializable_iterator()\n","# next_element = iterator.get_next()\n","# with tf.Session() as sess:\n","#         sess.run(iterator.initializer)\n","#         image_batch, label_batch = sess.run(next_element)\n","#         print(image_batch.shape)\n","#         print(label_batch.shape)\n","#         feature_map_batch = mobile_net(image_batch)\n","#         print(feature_map_batch.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c4-B8ToH_zEC","colab_type":"text"},"source":["### Build a model wrapped around MobileNet"]},{"cell_type":"markdown","metadata":{"id":"6avJ-671FI4d","colab_type":"text"},"source":["### temp model to check the shape of output"]},{"cell_type":"code","metadata":{"id":"9yE6ntP_DGbA","colab_type":"code","colab":{}},"source":["# model_temp = tf.keras.Sequential([\n","#   mobile_net,\n","#   tf.keras.layers.GlobalAveragePooling2D(),\n","#   tf.keras.layers.Dense(1)])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o__cQvI9FGGN","colab_type":"text"},"source":["Now it produces outputs of the expected shape:\n","\n"]},{"cell_type":"code","metadata":{"id":"AkjlHk7dBRMB","colab_type":"code","colab":{}},"source":["# iterator = keras_ds.make_initializable_iterator()\n","# next_element = iterator.get_next()\n","# with tf.Session() as sess:\n","#         sess.run(iterator.initializer)\n","#         sess.run(tf.global_variables_initializer())\n","#         image_batch, label_batch = sess.run(next_element)\n","#         print(image_batch.shape)\n","#         print(label_batch.shape)\n","        \n","#         logit_batch = model_temp(image_batch).eval()\n","\n","#         print(\"min logit:\", logit_batch.min())\n","#         print(\"max logit:\", logit_batch.max())\n","#         print()\n","\n","#         print(\"Shape:\", logit_batch.shape)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qiJahMuRFQyE","colab_type":"text"},"source":["## MobileNetV2 Model"]},{"cell_type":"markdown","metadata":{"id":"lpEpNuGlxt4c","colab_type":"text"},"source":["tf.keras.layers.GlobalAveragePooling2D layer to convert the features to a single n-element vector per image.\n","\n"]},{"cell_type":"code","metadata":{"id":"cR5_BQql5XFr","colab_type":"code","colab":{}},"source":["model = tf.keras.Sequential([\n","  mobile_net,\n","  tf.keras.layers.GlobalAveragePooling2D(),\n","#   tf.keras.layers.Dense(32, activation=tf.nn.relu),\n","#   tf.keras.layers.Dense(16, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(1)])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tfdRgNIoAaxe","colab_type":"text"},"source":["Compile the model to describe the training procedure:\n","\n"]},{"cell_type":"code","metadata":{"id":"IbZHsahrAbdb","colab_type":"code","colab":{}},"source":["# model.compile(optimizer=tf.train.AdamOptimizer(), \n","#               loss='binary_crossentropy',\n","#               metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pGGwa52j0H6W","colab_type":"text"},"source":["Since there are two classes, use a binary cross-entropy loss."]},{"cell_type":"code","metadata":{"id":"Cj9jf6W5vrdY","colab_type":"code","colab":{}},"source":["base_learning_rate = 0.0001\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IwJ_g1_6Amlc","colab_type":"text"},"source":["There are 2 trainable variables: the Dense weights and bias:"]},{"cell_type":"code","metadata":{"id":"-tWwpnBJAnw0","colab_type":"code","colab":{}},"source":["len(model.trainable_variables) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_eWBqRBAqXP","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tPs91Wl0GAVc","colab_type":"text"},"source":["**Train the model.**\n","\n","Normally you would specify the real number of steps per epoch, but for demonstration purposes only run 3 steps.\n","\n"]},{"cell_type":"code","metadata":{"id":"Jxl7pRIuvwV3","colab_type":"code","colab":{}},"source":["print(train_size, val_size, test_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmcJKpKtxpBs","colab_type":"code","colab":{}},"source":["import numpy as np\n","train_steps_per_epoch=np.ceil(train_size/BATCH_SIZE)\n","train_steps_per_epoch = np.int64(train_steps_per_epoch)\n","train_steps_per_epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RX1TOC0czsYX","colab_type":"code","colab":{}},"source":["valid_steps_per_epoch=np.ceil(val_size/BATCH_SIZE)\n","valid_steps_per_epoch = np.int64(valid_steps_per_epoch)\n","valid_steps_per_epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3ZhVop0wGGE","colab_type":"code","colab":{}},"source":["initial_epochs = 10\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lK5c6xJ5wWKg","colab_type":"code","colab":{}},"source":["loss0, accuracy0 = model.evaluate(valid_ds, steps = valid_steps_per_epoch-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3naW2AaiwZix","colab_type":"code","colab":{}},"source":["print(\"initial loss: {:.2f}\".format(loss0))\n","print(\"initial accuracy: {:.2f}\".format(accuracy0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qww9Jv7L09_d","colab_type":"code","colab":{}},"source":["history = model.fit(train_ds, \n","                    epochs=initial_epochs, \n","                    steps_per_epoch=train_steps_per_epoch, \n","                    validation_data = valid_ds, \n","                    validation_steps=valid_steps_per_epoch-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tcfej-Grn9F","colab_type":"code","colab":{}},"source":["history.history"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKkisbWcVj1d","colab_type":"code","colab":{}},"source":["test_steps_per_epoch=np.ceil(test_size/BATCH_SIZE)\n","test_steps_per_epoch = np.int64(test_steps_per_epoch)\n","test_steps_per_epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ad0ekp7WQkU","colab_type":"code","colab":{}},"source":["test_loss, test_acc = model.evaluate(test_ds, steps=test_steps_per_epoch-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YoZtGJRxWSAJ","colab_type":"code","colab":{}},"source":["print('Test accuracy:', test_acc)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yk9eCDMIw0t7","colab_type":"text"},"source":["### Plots: Learning curves\n","Let's take a look at the learning curves of the training and validation accuracy/loss when using the MobileNet V2 base model as a fixed feature extractor."]},{"cell_type":"code","metadata":{"id":"HxiegsgFw2rb","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()),1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G8YJwdvxQoWm","colab_type":"text"},"source":["### predict values"]},{"cell_type":"code","metadata":{"id":"EmpYMPZUQqRL","colab_type":"code","colab":{}},"source":["pred_vector = model.predict(test_ds, steps=test_steps_per_epoch-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TrJGdzKxS3nH","colab_type":"code","colab":{}},"source":["pred_vector.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IPiEfip8Qvc5","colab_type":"code","colab":{}},"source":["np.squeeze(pred_vector)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBhfv22CxAgh","colab_type":"code","colab":{}},"source":["np.where( np.absolute(np.squeeze(pred_vector)) > 0.5 )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sicBx3D3yOw8","colab_type":"code","colab":{}},"source":["np.sum(np.absolute(np.squeeze(pred_vector)) > 0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5K8TjBTBS7i5","colab_type":"code","colab":{}},"source":["# create a one-shot iterator\n","iterator = test_ds.make_initializable_iterator()\n","# extract an element\n","next_element = iterator.get_next()\n","with tf.Session() as sess:\n","        sess.run(iterator.initializer)\n","        image_batch, label_batch = sess.run(next_element)\n","#         print(image_batch.shape)\n","        print(np.squeeze(label_batch))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O05xHjpFSjvZ","colab_type":"text"},"source":["## Finetuning"]},{"cell_type":"code","metadata":{"id":"qa0JyiEISmIk","colab_type":"code","colab":{}},"source":["mobile_net.trainable = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywdNxS7ODMbv","colab_type":"code","colab":{}},"source":["# Let's take a look to see how many layers are in the base model\n","print(\"Number of layers in the base model: \", len(mobile_net.layers))\n","\n","# Fine tune from this layer onwards\n","fine_tune_at = 50\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","for layer in mobile_net.layers[:fine_tune_at]:\n","  layer.trainable =  False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MK6qOczpDPxp","colab_type":"code","colab":{}},"source":["model.compile(loss='binary_crossentropy',\n","              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w4NXadvmDXWu","colab_type":"code","colab":{}},"source":["len(model.trainable_variables)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pa6Q3JzfDZRu","colab_type":"code","colab":{}},"source":["fine_tune_epochs = 10\n","total_epochs =  initial_epochs + fine_tune_epochs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B98KAji5Dbxo","colab_type":"code","colab":{}},"source":["history = model.fit(train_ds, \n","                    epochs = total_epochs,\n","                    initial_epoch = initial_epochs,\n","                    steps_per_epoch = train_steps_per_epoch, \n","                    validation_data = valid_ds, \n","                    validation_steps = valid_steps_per_epoch-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GVXYjRchJ6jX","colab_type":"code","colab":{}},"source":["test_loss, test_acc = model.evaluate(test_ds, steps=3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k3hIgSXcHfva","colab":{}},"source":["print('Test accuracy:', test_acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhnDU7rcGJoD","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QC8BNVOaGb-2","colab_type":"text"},"source":["# Manually save weights"]},{"cell_type":"markdown","metadata":{"id":"Km4DAI3VB8aa","colab_type":"text"},"source":["### checkpoints"]},{"cell_type":"code","metadata":{"id":"6HlxchysGYnm","colab_type":"code","colab":{}},"source":["model.save_weights('./checkpoints/my_checkpoint')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tu6mZ0UfD1ZY","colab_type":"code","colab":{}},"source":["ls checkpoints/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ol3lvI_-Gzu8","colab_type":"text"},"source":[" **Restore the weights**"]},{"cell_type":"code","metadata":{"id":"eZL6VfTcGht-","colab_type":"code","colab":{}},"source":["new_model = model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OANECQQjHieL","colab_type":"code","colab":{}},"source":["new_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OgK_OjNsHled","colab_type":"code","colab":{}},"source":["new_model.load_weights('./checkpoints/my_checkpoint')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoYbGMrQHs1p","colab_type":"code","colab":{}},"source":["test_loss, test_acc = new_model.evaluate(test_ds, steps=3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"64IiLuQDIa_7","colab_type":"text"},"source":["### save architecture and weights with hdf5"]},{"cell_type":"code","metadata":{"id":"V1MZ5HyTIdy1","colab_type":"code","colab":{}},"source":["# serialize model to JSON\n","model_json = model.to_json()\n","with open(\"model.json\", \"w\") as json_file:\n","    json_file.write(model_json)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZmx69yvKaAB","colab_type":"code","colab":{}},"source":["# Save weights to disk\n","model.save_weights('path_to_my_weights.h5')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"76VHpbhZCQMQ","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.upload()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vu1JXHOaCVRD","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hW_JhO9hJJV3","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"splP-pbSIrpZ","colab_type":"code","colab":{}},"source":["# load json and create model\n","json_file = open('model.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = keras.models.model_from_json(loaded_model_json)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xOCLsWB2KWme","colab_type":"code","colab":{}},"source":["# load weights into new model\n","loaded_model.load_weights('path_to_my_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"45SZWYepLNyH","colab_type":"code","colab":{}},"source":["base_learning_rate = 0.0001\n","loaded_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"URk1jC9hJzZd","colab_type":"code","colab":{}},"source":["test_loss, test_acc = loaded_model.evaluate(test_ds, steps=3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VzKoMqjEQMb2","colab_type":"text"},"source":["### predict function"]},{"cell_type":"code","metadata":{"id":"MelhNeu7PBA1","colab_type":"code","colab":{}},"source":["from scipy.special import softmax\n","\n","\n","def out_probability(path_to_img):\n","  img = load_and_preprocess_image(path_to_img)\n","  img_arr = tf.Session().run(img)\n","  img_arr = img_arr.reshape((-1, 224, 224, 3))\n","  vectr = loaded_model.predict(img_arr, steps=1)\n","#   print(vectr)\n","\n","#   np.set_printoptions(precision=5)\n","#   m = softmax(vectr)\n","  return vectr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LhaLpy1pPjcV","colab_type":"code","colab":{}},"source":["out_probability('/content/images/ChinaSet_AllFiles/CXR_png/CHNCXR_0494_1.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PWGg-U1Q-Nr","colab_type":"code","colab":{}},"source":["results = []\n","\n","import os, os.path\n","len(os.listdir('/content/images/ChinaSet_AllFiles/CXR_png') )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b6P6FvocQp6c","colab_type":"code","colab":{}},"source":["filenames = []\n","for i in os.listdir('/content/images/ChinaSet_AllFiles/CXR_png'):\n","  path = os.path.join('/content/images/ChinaSet_AllFiles/CXR_png', i)\n","  filenames.append(i)\n","  m1 = out_probability(path)\n","  results.append(m1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENzxKdCiQtRw","colab_type":"code","colab":{}},"source":["np.sum(np.squeeze(np.array(results))<0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oBh-kF-gQumQ","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykNVQSEuhxes","colab_type":"code","colab":{}},"source":["!zip -r model.zip checkpoints"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J9YGsA2n4u6z","colab_type":"text"},"source":["I am following [this](https://www.tensorflow.org/alpha/tutorials/images/transfer_learning#add_a_classification_head) tutorial for binary class classification. While defining the model it is defined as follows and quotes:\n","\n","> Apply a tf.keras.layers.Dense layer to convert these features into a single prediction per image. You don't need an activation function here because this prediction will be treated as logit or a raw prediction value. Positive numbers predict class 1, negative numbers predict class 0.\n","\n","\n","\n","\n","```\n","model = tf.keras.Sequential([\n","  base_model,\n","  tf.keras.layers.GlobalAveragePooling2D(),\n","  tf.keras.layers.Dense(1)\n","])\n","```\n","and then its compiled as \n","```\n","base_learning_rate = 0.0001\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","```\n","\n","I have seen a similar model definition [here](https://www.tensorflow.org/tutorials/load_data/images#pipe_the_dataset_to_a_model) as follows:\n","\n","```\n","model = tf.keras.Sequential([\n","  mobile_net,\n","  tf.keras.layers.GlobalAveragePooling2D(),\n","  tf.keras.layers.Dense(len(label_names))])\n","\n","model.compile(optimizer=tf.train.AdamOptimizer(), \n","              loss=tf.keras.losses.sparse_categorical_crossentropy,\n","              metrics=[\"accuracy\"])\n","```\n","\n","In the above cases where no activation function is used, I observed predicted values take any real value(not in the range of [0,1]) and not a single negative value for example.\n","\n","```\n","model = tf.keras.Sequential([\n","  mobile_net,\n","  tf.keras.layers.GlobalAveragePooling2D(),\n","  tf.keras.layers.Dense(1)])\n","\n","base_learning_rate = 0.0001\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","np.squeeze(model.predict(test_ds, steps=test_steps_per_epoch))\n","\n","# array([0.8656062 , 1.1738479 , 1.3243774 , 0.43144074, 1.3459874 ,\n","       0.8830215 , 0.27673364, 0.61824167, 0.6811296 , 0.31660053,\n","       0.66832197, 0.9944696 , 1.1472682 , 0.643435  , 1.6108004 ,\n","       0.46332538, 1.0919437 , 0.9578197 , 1.176657  , 1.1019497 ,\n","       1.2280573 , 1.3852577 , 1.0576394 , 0.89174306, 0.75531614,\n","       0.77309614, 0.2964771 , 1.4851328 , 0.52786475, 0.8349319 ,\n","       0.6725186 , 0.850648  , 1.5454502 , 1.5105858 , 0.8132403 ,\n","       0.8769205 , 0.8270436 , 0.5637488 , 1.0141921 , 1.7030811 ,\n","       1.4353518 , 1.4161562 , 1.378978  , 0.501247  , 0.6213258 ,\n","       0.9437766 , 2.429086  , 1.2481798 , 0.6229276 , 0.37893608,\n","       1.3877648 , 1.0904361 , 1.0879816 , 0.42403704, 0.79637295,\n","       2.8160148 , 0.8214861 , 0.8503458 , 0.80563146, 1.4901325 ,\n","       1.0303755 , 0.77981436, 1.088749  , 0.71522933, 1.3340217 ,\n","       2.0090134 , 1.0075089 , 0.8950774 , 0.6173111 , 0.7857665 ,\n","       1.7411164 , 1.3057053 , 0.33380216, 0.76223296, 1.5859761 ,\n","       0.96682435, 0.6254643 , 1.4843993 , 1.1031054 , 0.6320849 ,\n","       0.01859415, 0.72086346, 1.1440296 , 0.29395923, 1.5440805 ,\n","       0.380056  , 1.7602444 , 0.6369114 , 0.7867059 , 1.1418453 ,\n","       1.8237758 , 0.2560327 , 2.6044023 , 1.5562654 , 0.737739  ,\n","       0.40826577], dtype=float32)\n","\n","```  \n","**QUESTION: 1**\n","\n","**so, how does tensorflow calculate accuracy based on such values? because these values are not 0 or 1, so what threshold value it uses to decide whether a sample is of class 1 or class 0**\n","\n","---\n","\n","In another [tutorial](https://www.tensorflow.org/tutorials/keras/basic_classification#setup_the_layers), I have seen the use of sigmoid or softmax activation function for the last layer.\n","\n","```\n","model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=(28, 28)),\n","    keras.layers.Dense(128, activation=tf.nn.relu),\n","    keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","```\n","similarly, I defined my model as follows:\n","\n","```\n","model = tf.keras.Sequential([\n","  mobile_net,\n","  keras.layers.GlobalAveragePooling2D(),\n","  keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","```\n","\n","and observed values get in range of [0,1]\n","```\n","np.squeeze(model.predict(test_ds, steps=test_steps_per_epoch))\n","\n","# array([0.5962706 , 0.41386074, 0.7369955 , 0.4375754 , 0.4081418 ,\n","       0.5233598 , 0.54559284, 0.58932847, 0.46750832, 0.73593813,\n","       0.49894634, 0.49055347, 0.37505004, 0.6098627 , 0.5756561 ,\n","       0.5219231 , 0.37050545, 0.5673407 , 0.5554987 , 0.531324  ,\n","       0.28257015, 0.74096835, 0.57002604, 0.46783662, 0.7368346 ,\n","       0.5332815 , 0.5606995 , 0.5541738 , 0.57862717, 0.40553188,\n","       0.46588784, 0.30736524, 0.43870398, 0.74726176, 0.71659195,\n","       0.27446586, 0.50352675, 0.43134567, 0.68349624, 0.38074452,\n","       0.5150338 , 0.7177907 , 0.61012363, 0.63375396, 0.43830383,\n","       0.5749217 , 0.4520418 , 0.42618847, 0.53284496, 0.55864084,\n","       0.55283684, 0.56968784, 0.5476512 , 0.47232378, 0.43477964,\n","       0.424371  , 0.5257551 , 0.4982109 , 0.6054718 , 0.45364827,\n","       0.5447099 , 0.5589619 , 0.6879043 , 0.43605927, 0.49726096,\n","       0.5986774 , 0.46806905, 0.45553213, 0.4558573 , 0.2709099 ,\n","       0.29398417, 0.42126212, 0.4208623 , 0.25966096, 0.5174277 ,\n","       0.5691663 , 0.6820154 , 0.66986185, 0.29530805, 0.5368336 ,\n","       0.6704497 , 0.4770817 , 0.58965963, 0.66673934, 0.44505033,\n","       0.3894297 , 0.53820807, 0.47612685, 0.3273378 , 0.6933465 ,\n","       0.54334545, 0.49939007, 0.5978731 , 0.49409997, 0.4585469 ,\n","       0.43943945], dtype=float32)\n","```\n","\n","**QUESTION: 2**\n","\n","**how accuracy in this case is calculated by tensorflow?**\n","\n","---\n","\n","**QUESTION: 3**\n","\n","**so what is the difference between using sigmoid activation and not using it in the last layer? when I used sigmoid activation function, accuracy of model somehow decreased by 10% than when I didn't used sigmoid function. Is this coincident or does it has to do anything with the use of activation function.**"]},{"cell_type":"code","metadata":{"id":"QcEPMoyy4v_2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOwSdAhDzwBq","colab_type":"text"},"source":["# caps\n"]},{"cell_type":"code","metadata":{"id":"72GprcxxzxIs","colab_type":"code","colab":{}},"source":["def margin_loss(y_true, y_pred):\n","    \"\"\"\n","    :param y_true: [None, n_classes]\n","    :param y_pred: [None, num_capsule]\n","    :return: a scalar loss value.\n","    \"\"\"\n","    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n","        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n","\n","    return K.mean(K.sum(L, 1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ni3hszNr0JVJ","colab_type":"code","colab":{}},"source":["def PrimaryCap(inputs, dim_vector, n_channels, kernel_size, strides, padding):\n","    \"\"\"\n","    Apply Conv2D `n_channels` times and concatenate all capsules\n","    :param inputs: 4D tensor, shape=[None, width, height, channels]\n","    :param dim_vector: the dim of the output vector of capsule\n","    :param n_channels: the number of types of capsules\n","    :return: output tensor, shape=[None, num_capsule, dim_vector]\n","    \"\"\"\n","    output = layers.Conv2D(filters=dim_vector*n_channels, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n","    outputs = layers.Reshape(target_shape=[-1, dim_vector])(output)\n","    return layers.Lambda(squash)(outputs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOcTxF-E0hkF","colab_type":"code","colab":{}},"source":["def squash(vectors, axis=-1):\n","    \"\"\"\n","    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n","    :param vectors: some vectors to be squashed, N-dim tensor\n","    :param axis: the axis to squash\n","    :return: a Tensor with same shape as input vectors\n","    \"\"\"\n","    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n","    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm)\n","    return scale * vectors\n","  \n","  "],"execution_count":0,"outputs":[]}]}